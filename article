Furthermore, deepfake offers multiple language dubbing, which easily disrupts the industry of voice acting. Since deepfakes allow the placement of a person’s face to another, it could create a new era of actors who don’t want to show their faces and could perform through facial expressions and body movements. However, it’s also a threat to current actors since all that’s needed is their face to make a production with lower costs. The value and demand for their performance could be easily diminished since they have become more replaceable.
Moreover, deepfakes could create a new population of malicious users- people with ill intentions of deceiving others. It is “a perfect weapon for purveyors of fake news who want to influence everything from stock prices to elections.” (Shao, 2020). This possibility makes deepfake a new-market disruption since it’s a new technology still in its infancy but is already widely accessible through mobile apps. Additionally, deepfakes are prominently used in pornography. While it does not disrupt a certain innovation, it poses a threat to the security of women as they are the most common target of deepfake porn. According to Sensity AI, a research company that has tracked online deepfake videos since December of 2018, 90-95% of deepfakes are nonconsensual porn. In this context, deepfakes can create a new population of users in the form of people who seek power through revenge porn (Hao, 2021).
In other cases, deepfakes have also been used to spread false information by creating videos of politicians and celebrities giving statements they have never made before in reality. Deepfake also extends to audio, with an example of John F. Kennedy reading a speech he never got to say before his death. 
Deduced from these examples, we can say deepfake can pose a threat to security to the public – not only to their identity through digital and social media but also their monetary assets in financial institutions can become at risk. This could also disrupt the role of moderators in social media as it has become harder to distinguish which is a real user or a deepfake. In a 2020 article by Vincent, it’s predicted that Facebook will have a hard time moderating deepfakes after a deepfake video of their CEO, Mark Zuckerberg, circulated on Instagram in that same year. Even if it was a form of misinformation, Facebook did not remove it as according to them, it was not violating any of its policies. Clearly, as deepfake is still relatively new, violations it causes are still being identified, while safety policies and guidelines are modified to accommodate these new additions.
